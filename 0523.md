
-----------------------------------------

sudo 

cd /etc/
more group
找到 sudo:x:27:test01

sudo vi /etc/group


sudo:x:27:test01,test02

init 6



沒成功
不要重開就能用

-----------------------------------------

python

for
while

9x9 表

for n1 in range(1,10):
	for n2 in range(1,10):
		ans = n1 * n2
		print(n1,"*",n2,"=",ans)

-----------------------------------------






-----------------------------------------
畫 線性迴歸 圖

import matplotlib.pyplot as plt



-----------------------------------------
監督式 
有資料 預測 訓練
分類 迴歸


非監督式 
沒資料 大量資料 推斷
分群 找相似 降維 壓縮



強化學習
邊作邊改進


-----------------------------------------
https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/466633/
鳶尾花

iris


[資料分析&機器學習] 第2.1講： 如何獲取資料？ Sklearn內建資料集
https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC2-1%E8%AC%9B-%E5%A6%82%E4%BD%95%E7%8D%B2%E5%8F%96%E8%B3%87%E6%96%99-sklearn%E5%85%A7%E5%BB%BA%E8%B3%87%E6%96%99%E9%9B%86-baa8f027ed7b

這個範例 是 json 格式 整個程式 是 帶入json
取出 json 在用 pandas 畫表格



from sklearn import datasets

iris = datasets.load_iris()

iris.keys()
Out[4]:
dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])

print(iris['DESCR'])
print(iris['data'])
print(iris['feature_names'])
import pandas as pd
x = pd.DataFrame(iris['data'], columns=iris['feature_names'])
x
y = pd.DataFrame(iris['target'], columns=['target_names'])
y
data = pd.concat([x,y], axis=1)
data

http://tiny.cc/io1kpz


午休
-----------------------------------------
分組討論報告 花了 2:30



-----------------------------------------
https://scikit-learn.org/stable/index.html
資料切割 用 train_test_split 


import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

iris = load_iris()
X = pd.DataFrame(iris.data)
y = pd.DataFrame(iris.target)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state = 123)

test_size=0.2 (切成 80%train 20%test)

X_train, 
X_test, 
y_train, 
y_test = 

train_test_split(
X, 
y, 
test_size=0.2, 
shuffle = True, 
random_state = 123
)


用四個變數接

train_data,
train_target,
test_size=0.4, 
random_state=0

https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html


sklearn.model_selection.train_test_split 隨機劃分訓練集和測試集


X_train,X_test, y_train, y_test =cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)


https://www.itread01.com/content/1545178350.html
sklearn.model_selection中train_test_split()函式

train_test_split()是sklearn.model_selection中的分離器函式，用於將陣列或矩陣劃分為訓練集和測試集，函式樣式為： X_train, X_test, y_train, y_test = train_test_split(train_data, train_target, test_size, random_state，shuffle)

引數解釋：
train_data：待劃分的樣本資料
train_target：待劃分的對應樣本資料的樣本標籤
test_size：1）浮點數，在0 ~ 1之間，表示樣本佔比（test_size = 0.3，則樣本資料中有30%的資料作為測試資料，記入X_test，其餘70%資料記入X_train，同時適用於樣本標籤）；2）整數，表示樣本資料中有多少資料記入X_test中，其餘資料記入X_train
random_state：隨機數種子，種子不同，每次採的樣本不一樣；種子相同，採的樣本不變（random_state不取，取樣資料不同，但random_state等於某個值，取樣資料相同，取0的時候也相同，這可以自己程式設計嘗試下，不過想改變數值也可以設定random_state = int(time.time())）
shuffle：洗牌模式，1）shuffle = False，不打亂樣本資料順序；2）shuffle = True，打亂樣本資料順序


import numpy as np
from sklearn.model_selection import train_test_split

X, y = np.arange(30).reshape((10, 3)), range(10)

X_train, X_test ,y_train, y_test= train_test_split(X, y,test_size=0.3, random_state = 20, shuffle=True)

print(X_train,'\n') 
print(X_test,'\n')
print(y_train,'\n')
print(y_test)



https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/466633/

Top 10 Python Libraries:
Python is an ocean of libraries that serve various purposes and as a Python developer, you must have sound knowledge of the best ones. To help you in this, here is an article that brings to you the Top 10 Python Libraries for machine learning which are:

TensorFlow
Scikit-Learn
Numpy
Keras
PyTorch
LightGBM
Eli5
SciPy
Theano
Pandas

Seaborn
Bokeh  
Plotly
NLTK 
Gensim 
Scrapy 
Statsmodels






引數解釋：
train_data：所要劃分的樣本特徵集
train_target：所要劃分的樣本結果
test_size：樣本佔比，如果是整數的話就是樣本的數量
random_state：是隨機數的種子。
隨機數種子：其實就是該組隨機數的編號，在需要重複試驗的時候，保證得到一組一樣的隨機數。比如你每次都填1，其他引數一樣的情況下你得到的隨機陣列是一樣的。但填0或不填，每次都會不一樣。
隨機數的產生取決於種子，隨機數和種子之間的關係遵從以下兩個規則：

種子不同，產生不同的隨機數；種子相同，即使例項不同也產生相同的隨機數。


需要注意的是，train_test_split默認會對原始數據進行shuffle，如果設置了stratify則會在不同的類別進行shuffle後選擇或者直接選擇。.


shuffle洗牌
stratify分層





sklearn中的random_state
很多人都把random_state解釋為隨機數種子。是不是很懵逼？什麼是隨機數種子？

我也不知道什麼是隨機數種子。但是，隨機數種子是為了保證每次隨機的結果都是一樣的

Example： sklarn可以隨機分割訓練集和測試集（交叉驗證），只需要在代碼中引入model_selection.train_test_split就可以了

代碼：

from sklearn import model_selection
x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=0)
這裡的random_state就是為了保證程序每次運行都分割一樣的訓練集合測試集。否則，同樣的算法模型在不同的訓練集和測試集上的效果不一樣。

當你用sklearn分割完測試集和訓練集，確定模型和促初始參數以後，你會發現程序每運行一次，都會得到不同的準確率，無法調參。這個時候就是因為沒有加random_state。加上以後就可以調參了。

如果你不知道如何高效調參，請參考：

使用TPOT自動選擇scikit-learn機器學習模型和參數

TPOT自動選擇機器學習模型和參數--回歸示例
————————————————
版权声明：本文为CSDN博主「水木小僧」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/Tony_Stark_Wang/java/article/details/80407923




python sklearn模型中random_state參數的意義

random_state 相當於隨機數種子random.seed() 。random_state 與random seed 作用是相同的。

隨機數種子代碼演示：在1-100中取10個隨機數
        
第一段和第二段代碼完全相同，都沒有設置random seed。它每次取的結果就不同，它的隨機數種子與當前系統時間有關。


random_state參數：
       
例如：在sklearn可以隨機分割訓練集和測試集（交叉驗證），只需要在代碼中引入model_selection.train_test_split就可以了：

from sklearn import model_selection

x_train, x_test, y_train,y_test=model_selection.train_test_split(x,y,test_size=0.2,random_state=0)

這裡的random_state就是為了保證程序每次運行都分割一樣的訓練集和測試集。否則，同樣的算法模型在不同的訓練集和測試集上的效果不一樣。
當你用sklearn分割完測試集和訓練集，確定模型和初始參數以後，你會發現程序每運行一次，都會得到不同的準確率，無法調參。這個時候就是因為沒有加random_state。加上以後就可以調參了



-----------------------------------------
[['a', 'b'], ['c', 'd']]
[['a', 'c'], ['d', 'b']]
[['a', 'd'], ['b', 'c']]
[['b', 'd'], ['c', 'a']]
[['d', 'b'], ['a', 'c']]
[['d', 'a'], ['c', 'b']]
[['d', 'a'], ['c', 'b']]


[2 3 4 5] [0 1]
[0 1 4 5] [2 3]
[0 1 2 3] [4 5]

[0 2 4 5] [1 3]
[1 2 3 5] [0 4]
[0 1 3 4] [2 5]
-----------------------------------------





-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------




-----------------------------------------


-----------------------------------------

-----------------------------------------













































